{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broken-prague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { margin-left: 0 !important; width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { margin-left: 0 !important; width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incoming-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "import cmath\n",
    "import glob\n",
    "import itertools\n",
    "import tensorboard\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "catholic-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example0:\n",
    "# {\n",
    "#   \"EntryType\":\"EquivalentLoudnessMeasurement\",\n",
    "#   \"Calibration\":{\n",
    "#     \"HeadphoneFrequencyResponseHash\":\"eab807a5050b0087109ac1fd6fecbd09197a3dcd\",\n",
    "#     \"FullScaleSineDBSPL\":100\n",
    "#   },\n",
    "#   \"Run\":{\n",
    "#     \"ID\":\"1599737802659_2857050667\"\n",
    "#   },\n",
    "#   \"Evaluation\":{\n",
    "#     \"ID\":\"1599738237070_2365796582\",\n",
    "#     \"Frequency\":697.9866246810275,\n",
    "#     \"Probe\":{\n",
    "#       \"Type\":\"Noise\",\n",
    "#       \"Params\":{\n",
    "#         \"Level\":-10,\n",
    "#         \"LowerLimit\":966.84025,\n",
    "#         \"Onset\":{\n",
    "#           \"Delay\":0,\n",
    "#           \"Duration\":0.1\n",
    "#         },\n",
    "#         \"UpperLimit\":1033.15975\n",
    "#       }\n",
    "#     },\n",
    "#     \"Combined\":{\n",
    "#       \"Type\":\"Superposition\",\n",
    "#       \"Params\":[\n",
    "#         {\n",
    "#           \"Params\":{\n",
    "#             \"Level\":-40,\n",
    "#             \"LowerLimit\":966.84025,\n",
    "#             \"Onset\":{\n",
    "#               \"Delay\":0.5,\n",
    "#               \"Duration\":0.1\n",
    "#             },\n",
    "#             \"UpperLimit\":1033.15975\n",
    "#           },\n",
    "#           \"Type\":\"Noise\"\n",
    "#         },{\n",
    "#           \"Params\":{\n",
    "#             \"Level\":-20,\n",
    "#             \"LowerLimit\":672.9766301106662,\n",
    "#             \"Onset\":{\n",
    "#               \"Delay\":0,\n",
    "#               \"Duration\":0.1\n",
    "#             },\n",
    "#             \"UpperLimit\":722.9966192513888\n",
    "#           },\n",
    "#           \"Type\":\"Noise\"\n",
    "#         }\n",
    "#       ]\n",
    "#     }\n",
    "#   },\n",
    "#   \"Results\":{\n",
    "#     \"ProbeGainForEquivalentLoudness\":0.003107877399956887,\n",
    "#     \"ProbeDBSPLForEquivalentLoudness\":39.84927756697657\n",
    "#   }\n",
    "# }\n",
    "def experiment_result_to_example(js, car_fs_sine_level=100, window_size=2048, sample_rate=48000):\n",
    "    exp = json.loads(js, object_hook=lambda o: SimpleNamespace(**o))\n",
    "    if exp.EntryType != 'EquivalentLoudnessMeasurement':\n",
    "        return None\n",
    "    assert exp.Evaluation.Probe.Type == 'Noise'\n",
    "    assert exp.Evaluation.Combined.Type == 'Superposition'\n",
    "    for part in exp.Evaluation.Combined.Params:\n",
    "        assert part.Type == 'Noise'\n",
    "    assert exp.Results.ProbeGainForEquivalentLoudness > 0\n",
    "    assert exp.Results.ProbeDBSPLForEquivalentLoudness != None\n",
    "    assert exp.Calibration.FullScaleSineDBSPL > 0\n",
    "        \n",
    "    bin_width = sample_rate / window_size\n",
    "    def add_noise(coeffs, lower_limit, upper_limit, total_power_db_fs):\n",
    "        first_bin = int(np.floor(lower_limit/bin_width))\n",
    "        last_bin = int(np.ceil(upper_limit/bin_width))\n",
    "        noise_coeffs = (complex(0, 1) * np.random.normal(size=[last_bin-first_bin]) + \n",
    "                        np.random.normal(size=[last_bin-first_bin]))\n",
    "        noise_power_db_fs = 10 * np.log10(np.sum(noise_coeffs ** 2))\n",
    "        scale = 10 ** ((total_power_db_fs - noise_power_db_fs) / 20)\n",
    "        noise_coeffs *= scale\n",
    "        for bin_idx in range(first_bin, first_bin + 1):\n",
    "            coeffs[bin_idx] += noise_coeffs[bin_idx - first_bin]\n",
    "            coeffs[-bin_idx] += np.conjugate(coeffs[bin_idx])\n",
    "    coeffs = np.zeros([window_size], dtype=np.complex64)\n",
    "    for part in exp.Evaluation.Combined.Params:\n",
    "        part_db_spl = exp.Calibration.FullScaleSineDBSPL + part.Params.Level\n",
    "        part_db_fs = part_db_spl - car_fs_sine_level\n",
    "        add_noise(coeffs, part.Params.LowerLimit, part.Params.UpperLimit, part_db_fs)\n",
    "    \n",
    "    relevant_bins = np.zeros([int(window_size/2)], dtype=np.complex64)\n",
    "    first_relevant_bin = int(np.floor(exp.Evaluation.Probe.Params.LowerLimit/bin_width))\n",
    "    last_relevant_bin = int(np.ceil(exp.Evaluation.Probe.Params.UpperLimit/bin_width))\n",
    "    for bin_idx in range(first_relevant_bin, last_relevant_bin + 1):\n",
    "        relevant_bins[bin_idx] = 1\n",
    "\n",
    "    true_loudness = np.array([exp.Results.ProbeDBSPLForEquivalentLoudness], dtype=np.complex64)\n",
    "    \n",
    "    res = tf.concat([coeffs, true_loudness, relevant_bins], axis=0)\n",
    "    return res\n",
    "\n",
    "def load_examples(glb, car_fs_sine_level=100, window_size=2048, sample_rate=48000, batch_size=32, repeat=1):\n",
    "    lines_iter = itertools.chain(*map(lambda f: open(f).readlines(), glob.glob(glb)))\n",
    "    examples_iter = map(lambda l: experiment_result_to_example(l, car_fs_sine_level=car_fs_sine_level, window_size=window_size, sample_rate=sample_rate), lines_iter)\n",
    "    filtered_iter = filter(lambda e: e != None, examples_iter)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(list(filtered_iter))\n",
    "    input_true_ds = ds.map(lambda ex: (ex[:window_size], ex[window_size:]))\n",
    "    repeated_ds = input_true_ds.repeat(repeat)\n",
    "    batched_ds = repeated_ds.batch(batch_size)\n",
    "    return batched_ds\n",
    "            \n",
    "def pz_plot():\n",
    "    _, ax = plt.subplots(figsize=(4,4))\n",
    "    ax.add_patch(patches.Circle((0,0),\n",
    "                              radius=1,\n",
    "                              fill=False,\n",
    "                              color='black',\n",
    "                              ls='solid',\n",
    "                              alpha=0.1))\n",
    "    ax.axvline(0, color='0.7')\n",
    "    ax.axhline(0, color='0.7')\n",
    "    ax.set_xlim((-1.1,1.1))\n",
    "    ax.set_ylim((-1.1,1.1))\n",
    "    return ax\n",
    "\n",
    "class PZLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, gain=complex(1.0, 0), poles=None, zeros=None, **kwargs):\n",
    "        super(PZLayer, self).__init__(**kwargs)\n",
    "        self._gain = tf.cast(gain, dtype=tf.complex128)\n",
    "        self._poles = tf.cast(poles, dtype=tf.complex128)\n",
    "        self._zeros = tf.cast(zeros, dtype=tf.complex128)\n",
    "    def get_config(self):\n",
    "        config = super(PZLayer, self).get_config()\n",
    "        config['gain'] = self._gain\n",
    "        config['poles'] = self._poles\n",
    "        config['zeros'] = self._zeros\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "        self._z = tf.exp(tf.complex(\n",
    "            real=tf.zeros(dtype=tf.float64, shape=[input_shape[1]]),\n",
    "            imag=tf.linspace(tf.cast(0.0, dtype=tf.float64),\n",
    "                             (input_shape[1] - 1)*2*math.pi/input_shape[1],\n",
    "                             input_shape[1]),\n",
    "            name='z'))\n",
    "    def add_to_plot(self, ax, offset):\n",
    "        for idx, pole in enumerate(self._poles):\n",
    "            ax.plot([tf.math.real(pole)], [tf.math.imag(pole)],\n",
    "                    'x', markersize=9, alpha=0.5)\n",
    "            ax.text(tf.math.real(pole), tf.math.imag(pole), \n",
    "                    r' ${}^{' + str(idx + offset) + '}$',\n",
    "                    fontsize=13)\n",
    "        for idx, zero in enumerate(self._zeros):\n",
    "            ax.plot([tf.math.real(zero)], [tf.math.imag(zero)],\n",
    "                    'o', color='none', markeredgecolor='red',\n",
    "                    markersize=9, alpha=0.5)\n",
    "            ax.text(tf.math.real(zero), tf.math.imag(zero), \n",
    "                    r' ${}^{' + str(idx + offset) + '}$',\n",
    "                    fontsize=13)\n",
    "    def plot(self):\n",
    "        self.add_to_plot(pz_plot(), 0)\n",
    "    # [...,fft_coeffs] => [...,fft_coeffs]\n",
    "    def call(self, input):\n",
    "        output = tf.cast(input, dtype=tf.complex128) * self._gain\n",
    "        for zero in self._zeros:\n",
    "            output *= self._z - zero\n",
    "            output *= self._z - tf.math.conj(zero)\n",
    "        denom = tf.ones(self._z.shape, dtype=tf.complex128)\n",
    "        for pole in self._poles:\n",
    "            denom *= self._z - pole\n",
    "            denom *= self._z - tf.math.conj(pole)\n",
    "        output /= denom\n",
    "        return tf.cast(output, dtype=input.dtype)\n",
    "\n",
    "class CARLayer(tf.keras.layers.Layer):\n",
    "    # See 'Human and Machine Hearing', 16.2-16.3,\n",
    "    # and https://github.com/google/carfac/.\n",
    "    def __init__(self, sample_rate=48000, erb_per_step=0.5, **kwargs):\n",
    "        super(CARLayer, self).__init__(**kwargs)\n",
    "\n",
    "        self._erb_per_step = erb_per_step\n",
    "        self._sample_rate = sample_rate\n",
    "\n",
    "        # Based on the assumtion that max small-signal gain at the passband peak\n",
    "        # will be on the order of  (0.5/min_zeta)^(1/erb_per_step), and we need\n",
    "        # the start value of that in the same region or the loss function becomes\n",
    "        # too uneven to optimize.\n",
    "        def compute_zeta(zeta_at_default_erb_per_step, erb_per_step):\n",
    "            default_erb_per_step = 0.5\n",
    "            max_small_signal_gain = (0.5 /\n",
    "                                     zeta_at_default_erb_per_step) ** (1 /\n",
    "                                                           default_erb_per_step)\n",
    "            return 0.5 / (max_small_signal_gain ** erb_per_step)\n",
    "\n",
    "        # Controls r (pole and zero abs value) which controls damping relative to\n",
    "        # frequency.\n",
    "        self._high_f_damping_compression = self.add_weight(\n",
    "             name='high_f_damping_compression',\n",
    "             initializer=tf.keras.initializers.Constant(0.5),\n",
    "             trainable=self.trainable)\n",
    "        # Controls distance from pole to zero.\n",
    "        self._zero_ratio = self.add_weight(\n",
    "            name='zero_ratio',\n",
    "            initializer=tf.keras.initializers.Constant(2 ** 0.5),\n",
    "            trainable=self.trainable)\n",
    "        # min/max zeta controls max damping.\n",
    "        self._min_zeta = self.add_weight(\n",
    "            name='min_zeta',\n",
    "            initializer=tf.keras.initializers.Constant(compute_zeta(0.1, erb_per_step)),\n",
    "            trainable=self.trainable)\n",
    "        self._max_zeta = self.add_weight(\n",
    "            name='max_zeta',\n",
    "            initializer=tf.keras.initializers.Constant(compute_zeta(0.35, erb_per_step)),\n",
    "            trainable=self.trainable)\n",
    "        self._erb_constant_0 = self.add_weight(\n",
    "            name='erb_constant_0(24.7)',\n",
    "            initializer=tf.keras.initializers.Constant(24.7),\n",
    "            trainable=self.trainable)\n",
    "        self._erb_constant_1 = self.add_weight(\n",
    "            name='erb_constant_1(1.0)',\n",
    "            initializer=tf.keras.initializers.Constant(1),\n",
    "            trainable=self.trainable)\n",
    "        self._erb_constant_2 = self.add_weight(\n",
    "            name='erb_constant_2(4.37)',\n",
    "            initializer=tf.keras.initializers.Constant(4.37),\n",
    "            trainable=self.trainable)\n",
    "        max_freq = 20000\n",
    "        min_freq = 20\n",
    "\n",
    "        def ERB(f):\n",
    "            return self._erb_constant_0 * (self._erb_constant_1 + self._erb_constant_2 * f * 0.001)\n",
    "\n",
    "        pole_freqs = [max_freq]\n",
    "        while pole_freqs[-1] - erb_per_step * ERB(pole_freqs[-1]) > min_freq:\n",
    "            pole_freqs.append(pole_freqs[-1] - erb_per_step * ERB(pole_freqs[-1]))\n",
    "        self._pole_freqs = np.array(pole_freqs)\n",
    "\n",
    "        # From the matlab code:\n",
    "        # zero_ratio comes in via h.  In book's circuit D, zero_ratio is 1/sqrt(a),\n",
    "        # and that a is here 1 / (1+f) where h = f*c.\n",
    "        # solve for f:  1/zero_ratio^2 = 1 / (1+f)\n",
    "        # zero_ratio^2 = 1+f => f = zero_ratio^2 - 1\n",
    "        f = self._zero_ratio ** 2 - 1\n",
    "        pole_thetas = self._pole_freqs * 2 * np.pi / sample_rate\n",
    "        # The book assigns a0 and c0 thus to simplify the equations.\n",
    "        a0 = np.cos(pole_thetas)\n",
    "        c0 = np.sin(pole_thetas)\n",
    "\n",
    "        # The ratio between each pole and max measurable frequency.\n",
    "        x = pole_thetas / np.pi\n",
    "\n",
    "        # From the matlab code:\n",
    "        # When high_f_damping_compression is 0 this is just theta, when\n",
    "        # high_f_damping_compression is 1 it approaches 0 as theta approaches pi.\n",
    "        zr_coeffs = np.pi * (x - self._high_f_damping_compression * x ** 3)\n",
    "\n",
    "        # The book is not super easy to follow here, so I have mostly\n",
    "        # implemented the same math as the matlab and c++ code.\n",
    "\n",
    "        r1 = (1 - zr_coeffs * self._max_zeta)\n",
    "        min_zetas = self._min_zeta + (0.25 * ((ERB(self._pole_freqs) / pole_freqs) - self._min_zeta))\n",
    "        zr_coeffs *= (self._max_zeta - min_zetas)\n",
    "        r = r1 + zr_coeffs\n",
    "        h = c0 * f\n",
    "        g0 = (1 - 2 * r * a0 + r ** 2) / (1 - 2 * r * a0 + h * r * c0 + r ** 2)\n",
    "        self._poles = tf.cast(r, dtype=tf.complex128) * np.exp(complex(0, 1) * pole_thetas)\n",
    "        zero_thetas = np.arccos(a0 - h * c0 / 2)\n",
    "        self._zeros = tf.cast(r, dtype=tf.complex128) * np.exp(complex(0, 1) * zero_thetas)\n",
    "\n",
    "        # Here is where I diverge a lot, by just creating frequency domain filters\n",
    "        # instead of difference equations.\n",
    "        self._filters = [\n",
    "          PZLayer(gain=g0[idx],\n",
    "                  poles=[self._poles[idx]],\n",
    "                  zeros=[self._zeros[idx]],\n",
    "                  name='ar{idx}'.format(idx=idx)) for idx in range(len(self._poles))]\n",
    "\n",
    "    def plot_outputs(self, inputs, figsize=(12,4)):\n",
    "        half_inputs = int(inputs.shape[0] / 2)\n",
    "        xaxis = np.linspace(0,\n",
    "                            (inputs.shape[0] - 1) * self._sample_rate *\n",
    "                            0.5 / inputs.shape[0],\n",
    "                            inputs.shape[0])\n",
    "        _, ax = plt.subplots(figsize=figsize)    \n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlim((10,20000))\n",
    "        ax.set_ylim((-20, 70))\n",
    "        outputs = self(tf.expand_dims(inputs, 0))[0]\n",
    "        for output in outputs:\n",
    "            ax.plot(xaxis[:half_inputs],\n",
    "                    20 * np.log(np.abs(output[:half_inputs])) / np.log(10))\n",
    "    def plot(self):\n",
    "        ax = pz_plot()\n",
    "        for idx, filter in enumerate(self._filters):\n",
    "            filter.add_to_plot(ax, idx)\n",
    "    def get_config(self):\n",
    "        config = super(CARLayer, self).get_config()\n",
    "        config['erb_per_step'] = self._erb_per_step\n",
    "        config['sample_rate'] = self._sample_rate\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "        for filter in self._filters:\n",
    "            filter.build(input_shape)\n",
    "    # [...,fft_coeffs] => [...,channels,fft_coeffs]\n",
    "    def call(self, inputs):\n",
    "        output_ary = []\n",
    "        outputs = inputs\n",
    "        for idx in range(len(self._filters)):\n",
    "            outputs = self._filters[idx](outputs)\n",
    "            output_ary.append(tf.expand_dims(outputs, 1))\n",
    "        res = tf.concat(output_ary, 1)\n",
    "        return res\n",
    "\n",
    "class EarLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, car_params={}, **kwargs):\n",
    "        super(EarLayer, self).__init__(**kwargs)\n",
    "        if 'sample_rate' in car_params and car_params['sample_rate'] != 48000:\n",
    "            raise \"must use sample rate 48000\"  # Since the _outer_middle layer params are optimized for 48k.\n",
    "        car_params['sample_rate'] = 48000\n",
    "        self._car_params = car_params\n",
    "        # Numbers from https://colab.corp.google.com/drive/161a2riUCQeYYEPhlRc7XqtI9OWUMwQQX?usp=sharing.\n",
    "        self._outer_middle = PZLayer(\n",
    "            gain=1.34,\n",
    "            poles=[(-0.05429768147702485+1.4172655611120915e-05j),\n",
    "                   (0.2917622403739163+0.7731812636894612j),\n",
    "                   (0.8768382244780407-0.31120458350060115j),\n",
    "                   (0.6598943546882394-0.46728573398560225j)],\n",
    "            zeros=[(0.635496172349615+0.14499945287904842j),\n",
    "                   (0.30987058966944614-0.8574194617385421j),\n",
    "                   (0.5721096307971768-2.2915816453724273e-05j)])\n",
    "        self._cochlea = CARLayer(**car_params)\n",
    "    def build(self, input_shape):\n",
    "        self._outer_middle.build(input_shape)\n",
    "        self._cochlea.build(input_shape)\n",
    "    def get_config(self):\n",
    "        config = super(PZLayer, self).get_config()\n",
    "        config['car_params'] = self._car_params\n",
    "        return config\n",
    "    # [...,fft_coeffs] => [...,channels,fft_coeffs]\n",
    "    def call(self, inputs):\n",
    "        res = inputs\n",
    "        res = self._outer_middle(res)\n",
    "        res = self._cochlea(res)\n",
    "        return res\n",
    "\n",
    "class EarSNRLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, ear_params={}, **kwargs):\n",
    "        super(EarSNRLayer, self).__init__(**kwargs)\n",
    "        self._ear_params = ear_params\n",
    "        self._ear = EarLayer(**ear_params)\n",
    "    def get_config(self):\n",
    "        config = super(EarSNRLayer, self).get_config()\n",
    "        config['ear_params'] = self._ear_params\n",
    "        return config\n",
    "    def plot_outputs(self, inputs):\n",
    "        snr = self(tf.expand_dims(inputs, 0))[0]\n",
    "        max_snr = np.nanmax(snr)\n",
    "        min_snr = np.nanmin(snr)\n",
    "        scaled_snr = np.expand_dims((snr - min_snr) / (max_snr - min_snr), 2)\n",
    "        pixels = np.concatenate([scaled_snr, scaled_snr/2, scaled_snr/2], axis=2)\n",
    "        plt.figure(figsize = (20,10))\n",
    "        plt.imshow(pixels, interpolation='bicubic')\n",
    "    # [...,fft_coeffs] => [...,channels,db_snr]\n",
    "    def call(self, inputs):\n",
    "        ear_out = self._ear(inputs)\n",
    "        gain = tf.abs(ear_out)\n",
    "        epsilon = 1e-20\n",
    "        signal_power = tf.maximum(gain * gain, epsilon)\n",
    "        noise_power = tf.maximum(tf.expand_dims(tf.math.reduce_sum(signal_power, axis=2), 2) - signal_power, epsilon)\n",
    "        snr = signal_power / noise_power\n",
    "        res = 10.0 * tf.math.log(snr) / tf.cast(tf.math.log(10.0), dtype=signal_power.dtype)\n",
    "        res = res[:,:,:int(res.shape[2]/2)]\n",
    "        return res\n",
    "\n",
    "class LoudnessPredictorLoss(tf.keras.losses.Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        true_partial_loudness = y_true[:,0]\n",
    "        min_psnr = tf.expand_dims(tf.math.reduce_min(y_pred, axis=1), 1)\n",
    "        relevant_bins = tf.cast(y_true[:,1:], dtype=tf.bool)\n",
    "        reduced_irrelevant_bins = tf.where(relevant_bins, y_pred, min_psnr - 1)\n",
    "        psnr_across_relevant_bins = tf.math.reduce_max(reduced_irrelevant_bins, axis=1)\n",
    "        res = tf.keras.losses.MSE(true_partial_loudness, psnr_across_relevant_bins)\n",
    "        return res\n",
    "\n",
    "class LoudnessPredictorLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, ear_params={}, **kwargs):\n",
    "        super(LoudnessPredictorLayer, self).__init__(**kwargs)\n",
    "        self._ear_params = ear_params\n",
    "        self._ear = EarSNRLayer(ear_params=ear_params)\n",
    "        self._loudness_offset = self.add_weight(\n",
    "            name='loudness_offset',\n",
    "            dtype=self.dtype,\n",
    "            initializer=tf.keras.initializers.Constant(0),\n",
    "            trainable=self.trainable,\n",
    "        )\n",
    "        self._loudness_scale = self.add_weight(\n",
    "            name='loudness_scale',\n",
    "            dtype=self.dtype,\n",
    "            initializer=tf.keras.initializers.Constant(1),\n",
    "            trainable=self.trainable,\n",
    "        )\n",
    "    def plot_snr(self, inputs):\n",
    "        self._ear.plot_outputs(inputs)\n",
    "    def get_config(self):\n",
    "        config = super(LoudnessPredictorLayer, self).get_config()\n",
    "        config['ear_params'] = self._ear_params\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "        self._ear.build(input_shape)\n",
    "        # [...,fft_bin] => [...,equivalent_db_spl]\n",
    "    def call(self, inputs):\n",
    "        snr = self._ear(inputs)\n",
    "        psnr_per_bin = tf.math.reduce_max(snr, axis=1)\n",
    "        res = self._loudness_offset + self._loudness_scale * psnr_per_bin\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "novel-commerce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 2048), dtype=complex64, numpy=\n",
      "array([[0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "       [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "       [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "       ...,\n",
      "       [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "       [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "       [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j]],\n",
      "      dtype=complex64)>, <tf.Tensor: shape=(32, 1025), dtype=complex64, numpy=\n",
      "array([[52.7015  +0.j,  0.      +0.j,  0.      +0.j, ...,  0.      +0.j,\n",
      "         0.      +0.j,  0.      +0.j],\n",
      "       [52.29769 +0.j,  0.      +0.j,  0.      +0.j, ...,  0.      +0.j,\n",
      "         0.      +0.j,  0.      +0.j],\n",
      "       [52.1291  +0.j,  0.      +0.j,  0.      +0.j, ...,  0.      +0.j,\n",
      "         0.      +0.j,  0.      +0.j],\n",
      "       ...,\n",
      "       [22.800282+0.j,  0.      +0.j,  0.      +0.j, ...,  0.      +0.j,\n",
      "         0.      +0.j,  0.      +0.j],\n",
      "       [ 9.274953+0.j,  0.      +0.j,  0.      +0.j, ...,  0.      +0.j,\n",
      "         0.      +0.j,  0.      +0.j],\n",
      "       [ 9.957078+0.j,  0.      +0.j,  0.      +0.j, ...,  0.      +0.j,\n",
      "         0.      +0.j,  0.      +0.j]], dtype=complex64)>)\n"
     ]
    }
   ],
   "source": [
    "one_khz_examples = load_examples('/home/zond/DriveFileStream/My Drive/korvapuusti/listening_tests/modern_format/by_probe_center/1kHz/*/*.json')\n",
    "for ex in one_khz_examples.take(1):\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fifty-hotel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 2048\n",
    "for ex in one_khz_examples.take(1):\n",
    "    ex0 = ex\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(np.arange(window_size), np.abs(ex0[0][0,:window_size]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "verified-practitioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lpl = LoudnessPredictorLayer()\n",
    "lpl.plot_snr(ex0[0][0,:window_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method EarSNRLayer.call of <__main__.EarSNRLayer object at 0x7fed7ac3d3d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpq5lfebsd.py, line 17)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method EarSNRLayer.call of <__main__.EarSNRLayer object at 0x7fed7ac3d3d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpq5lfebsd.py, line 17)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LoudnessPredictorLoss.call of <__main__.LoudnessPredictorLoss object at 0x7fed7ab0cdf0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpasfcgxwv.py, line 10)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LoudnessPredictorLoss.call of <__main__.LoudnessPredictorLoss object at 0x7fed7ab0cdf0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpasfcgxwv.py, line 10)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['high_f_damping_compression:0', 'zero_ratio:0', 'min_zeta:0', 'max_zeta:0', 'erb_constant_0(24.7):0', 'erb_constant_1(1.0):0', 'erb_constant_2(4.37):0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['high_f_damping_compression:0', 'zero_ratio:0', 'min_zeta:0', 'max_zeta:0', 'erb_constant_0(24.7):0', 'erb_constant_1(1.0):0', 'erb_constant_2(4.37):0'] when minimizing the loss.\n",
      "14/14 - 10s - loss: 2467.6597\n",
      "Epoch 2/10\n",
      "14/14 - 1s - loss: 2467.1221\n",
      "Epoch 3/10\n",
      "14/14 - 1s - loss: 2466.5903\n",
      "Epoch 4/10\n",
      "14/14 - 1s - loss: 2466.0569\n"
     ]
    }
   ],
   "source": [
    "logdir=\"/home/zond/tmp/tensor_ears/logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "inputs = tf.keras.Input(shape=[window_size])\n",
    "lpm = tf.keras.models.Model(inputs=inputs, outputs=lpl(inputs))\n",
    "lpm.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=LoudnessPredictorLoss())\n",
    "lpm.fit(one_khz_examples, epochs=10, verbose=2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpl.plot_snr(ex0[0][0,:window_size])\n",
    "print(lpl._loudness_offset, lpl._loudness_scale, lpl._ear._ear._cochlea._zero_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "ear = EarSNRLayer()\n",
    "ear.plot_outputs(ex0[0][0,:window_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = CARLayer(erb_per_step=0.5)\n",
    "cl.plot()\n",
    "cl.plot_outputs(np.ones([48000], dtype=np.complex128), figsize=(24,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "pz = PZLayer(\n",
    "        gain=1.34,\n",
    "        poles=[(-0.05429768147702485+1.4172655611120915e-05j), (0.2917622403739163+0.7731812636894612j), (0.8768382244780407-0.31120458350060115j), (0.6598943546882394-0.46728573398560225j)],\n",
    "        zeros=[(0.635496172349615+0.14499945287904842j), (0.30987058966944614-0.8574194617385421j), (0.5721096307971768-2.2915816453724273e-05j)])\n",
    "pz.plot()\n",
    "z = np.ones([1, 1024], dtype=np.complex128)\n",
    "fy = tf.math.abs(pz(z)[0])\n",
    "y = 20 * np.log10(fy[:int(len(fy)/2)])\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.xscale('log')\n",
    "plt.plot(np.arange(0, len(y)), y)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
